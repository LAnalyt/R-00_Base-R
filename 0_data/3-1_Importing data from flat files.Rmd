---
title: "IMPORT DATA FROM FLAT FILES WITH UTILS"
source: DataCamp
---

Importing data into R should be the easiest step in your analysis. Unfortunately, that is almost never the case. Data can come in many formats, ranging from .csv and text files, to statistical software files, to databases and HTML data. Knowing which approach to use is key to getting started with the actual analysis.

<img src = "https://raw.githubusercontent.com/Lsinfos/R_00_Base-R/master/2_resources/import_5%20types.JPG" width = "300">

### 1.1 read.csv
Flat files are typically simple text files that display data as tables. The standard distribution of R provides functionality in built-in **utils** package to import flat files into R as a data frame, which is loaded automatically when we start R.
csv data is a flat file where csv stands for "comma separated values". For example, import the *states.csv* file with `read.csv()` function.  The first line gives the names of the different columns or fields. After that, each line is a record, and the fields are separated by a comma. 
```{r}
df <- read.csv("states.csv", stringsAsFactors = TRUE)
df
```
The structure nicely corresponds the data frame in R. The rows  correspond to the records and the columns correspond to the fields. The field names are used to name the columns of the data frame. 
First argument is the path to the imported file or the file name in current working directory. Depending on which platform you are working on, Microsoft, Linux, Mac..., file paths are specified differently.

To build a path to a file in a platform-independent way, use `file.path()` function. Suppose the file is located in the `0_data` of the home directory:
```{r}
path <- file.path("~", "0_data", "states.cv")
path
```
This path can now be used to point to the direct file.

Second argument `stringsAsFactors` chooses to import columns that contains strings as actual strings or as factors. By default, `stringsAsFactors = FALSE`.
```{r}
str(df) 
```
To list the files in the working directory, use `dir()`.

Import *swimming_pools.csv* which contains data on swimming pools in Brisbane, Australia:
```{r}
pools <- read.csv("swimming_pools.csv")
str(pools)
```

### 1.2 read.delim
Another common format of flat file data is the tab-delimited file, like *.txt* file. To import the same *states* data but in .txt format, we need `read.delim()` function.
```{r}
read.delim("states.txt")
```
If the data comes in typical comma separated or tab-delimited format, importing flat files is an easy task. If not, you will have to do some more customization work.
By default, `read.delim()` sets the `sep` argument to `\t` (fields in a record are delimited by tabs) and the `header` argument to `TRUE` (the first row contains the field names). 

Import *hotdogs.txt* which contains information on sodium and calorie levels in different hotdogs:
```{r}
hotdogs <- read.delim("hotdogs.txt", header = FALSE) 
```
The variable names are not on the first line. Print out some summary statistics about all variables in the data frame:
```{r}
summary(hotdogs)
```
Specify the column types or column classes of the resulting data frame with `colClasses` argument:
```{r}
hotdogs <- read.delim("hotdogs.txt", 
                      header = FALSE, 
                      col.names = c("type", "calories", "sodium"),
                      colClasses = c("factor", "NULL", "numeric"))
str(hotdogs)
```
If a column is set to `NULL` in the `colClasses` vector, this column will be skipped and will not be loaded into the data frame. 
This approach can be useful if you have some columns that should be factors and others that should be characters. You don't have to bother with `stringsAsFactors` anymore; just state for each column what the class should be.

### 1.3 read.table
If you're dealing with more exotic flat file formats, you'll want to use `read.table()` which allows you to read in any file in table format and create a data frame from it. For example, the same *states* data with the values being separated by `/` instead of `,` or `tab`. 
```{r}
read.table("states2.txt",
           header = TRUE,
           sep = "/")
```
The number of arguments is huge, some main ones are:

-    *states2.txt*: path to the imported file
-    `header`: tells R the first row of the text file contains variable names. By default `header = FALSE`, which means the first row is always read as an observation.
-    `sep`: specifies how fields in a record are separated. By default `sep = " "`.

Import the *hotdogs.txt* again, this time with `read.table()` with an argument to name the columns:
```{r}
hotdogs <- read.table("hotdogs.txt", 
           sep = "",
           col.names = c("type", "calories", "sodium"),
           stringsAsFactors = TRUE)
head(hotdogs)
```
Next to calories and sodium, the hotdogs have one more variable: `type`. This is a categorical variable because it can be only one of three things: Beef, Meat, or Poultry. Select the hot dog with the least calories:
```{r}
hotdogs[which.min(hotdogs$calories), ]
```
Select the observation with the most sodium:
```{r}
hotdogs[which.max(hotdogs$sodium), ]
```

### 1.4 Wrappers
`read.table()` is the main function of the **utils** package. `read.csv()` and `read.delim()` are so called *wrapper* functions around `read.table()`. Behind the scenes, `read.table()` is called, but with different default arguments to match the specific formats.
```{r}
read.csv("states.csv")
```
is the same as:
```{r}
read.table("states.csv", 
           header = TRUE, 
           sep = ",",
           stringsAsFactors = FALSE)
```
So you don't have to specify manually these anymore. Wrappers are shorter and easier to read.

Likewise `read.delim()` is the same as:
```{r}
read.delim("states.txt",
           header = TRUE,
           sep = "\t")
```
`read.csv2()` and `read.delim2()` exist to deal with regional differences in representing numbers. For example, `read.csv()` doesn't always give the result we want, because the values are separated by a `;`, not a `,`.
```{r}
read.csv("states_nay.csv")
```
Try again with `read.csv2()`:
```{r}
read.csv2("states_nay.csv")
```
It works perfectly, because the default argument `sep = ";"`.

`read.delim2()` has a default argument to convert the European decimal system with `,` into the US `.`
```{r}
read.delim("states_aye.txt")
read.delim2("states_aye.txt")
```

### 1.5 scan
When reading in spreadsheets many things can go wrong. The file might have a multiline header, be missing cells, or it might use an unexpected encoding. `scan()` helps you read-in each cell of a file.
```{r}
scan("states.csv", sep = ",", what = "c")
```

### 1.6 readr
In addition to base R, there are dedicated packages to easily and efficiently import flat file data. 
**readr** package which is written by Hadley Wickham is fast and easy to use with consistent naming, while **utils** is more verbose and multiple times slower.
```{r}
library(readr) 
```
Import the *states.csv* file again with **utils** to compare the difference:
```{r}
read.csv("states.csv", stringsAsFactors = FALSE) # return a data frame.
```
Similar function like `read.csv` in **readr** is `read_csv`:
```{r}
read_csv("states.csv")
```
The result is pretty much the same. The only difference is `read_csv` ouputs a *tibble*, which is a supercharged version of data frame. The printout conveniently shows the column classes.

In both calls, the first argument is the path to the file you want to import. In **readr**, strings are not imported as factors default, so an equivalent to `stringsAsFactors` argument is not required. 

**utils** features the `read.delim()` to import tab-delimited files. 
```{r}
read.delim("states.txt", stringsAsFactors = FALSE)
```
**readr** also provides similar function `read_tsv` (tab separated value).
```{r}
read_tsv("states.txt")
```
Just like in **utils** package, both `read_csv` and `read_tsv` are wrappers around the mother import function `read_delim()`.

<img src = "https://raw.githubusercontent.com/Lsinfos/R_00_Base-R/master/2_resources/import_wrapper.JPG" width = "450">

Now working with another dataset: *potatoes.csv*. It gives information on the impact of storage period and cooking on potatoes' flavor. It uses commas to delimit fields in a record, and contains column names in the first row. Import the "potatoes.csv" data:
```{r}
read_csv("potatoes.csv") 
```
This time, the potatoes data comes in the form of a tab-separated values file: *potatoes.txt*.
```{r}
read_tsv("potatoes.txt")
```
This *.txt* file does not contain columns names in the first row. This can be specify manually.
```{r}
properties <- c("area", "temp", "size", "storage", "method", "texture", "flavor", "moistness")
potatoes <- read_tsv("potatoes.txt", col_names = properties)
head(potatoes)
```

Use the low-level `read_delim` from **readr** to read the *.txt* files with values using `/` as separators:
```{r}
read_delim("states2.txt", delim = "/")
```
`delim` argument specifies the character that is used to separate fields within a record. It is equivalent to the `sep` argument in `read.table()`. The output corresponds to the output of `read.table()` but **readr** version outputs a tibble again.

We do not have to specify `header = TRUE` because by default, `read_delim()` expects the first row to contain the column names. It does this with the `col_names` argument. Setting `header = FALSE` leads to automatic generation of column names.

Also, strings are not imported as factors by default, so `stringsAsFactors` equivalent is not necessary.
```{r}
read_delim("states3.txt", delim ="/", 
           col_names = FALSE) # first line is a record. 
```
You can also manually set `col_names` to a character vector. The names you pass will be used as the names of the columns, and the first line is read as a record.
```{r}
read_delim("states3.txt", delim = "/",
           col_names = c("state", "city", "pop", "area"))
```
`col_types` controls the column classes (similar to `colClasses` in **utils**). If `col_type` is set to `NULL`, the default, functions from **readr** will try to find the correct types themselves. You can manually set the types with a string, where each character denotes the class of the column: character, double, integer and logical. `_` skips the column as a whole.
```{r}
read_delim("states2.txt", delim = "/",
           col_types = "ccdi") # c: character, d: double, i: integer.
```
If you are working on huge flat files, say one million lines, yo mighr be interested in handling data in chunks of 50.000 lines, for example. This keeps your work tractable and you can easily follow up the progress of your algorithms. In **readr** you can do this with the combination of `skip` and `n_max`. 

`n_max` controls which part of your flat file you're actually importing into R.
`skip`: specifies the number of lines you're ignoring in the flat file before actually starting to import data.
```{r}
read_delim("states2.txt", delim = "/",
           col_names = c("state", "city", "pop", "area"),
           skip = 2, n_max = 3)
```
Use `read_delim` to import *potatoes.txt* instead of `read_tsv`:
```{r}
read_delim("potatoes.txt", delim = "\t",
           col_names = properties)
```
Import observations 7, 8, 9, 10 and 11 only:
```{r}
read_delim("potatoes.txt", delim = "\t",
           skip = 6, n_max = 5,
           col_names = properties)
```
You can specify which types the columns with `col_types`. If `col_type` is set to `NULL`, the default, functions from **readr** will try to find the correct types themselves. You can manually set the types with a string, where each character denotes the class of the column: character, double, integer and logical. _ skips the column as a whole.
```{R}
potatoes_char <- read_tsv("potatoes.txt", col_types = "cccccccc", col_names = properties)
str(potatoes_char)
```
Another way of setting the types of the imported columns is using collectors. Collector functions can be passed in a `list()` to the `col_types` argument of `read_` function to tell them how to interpret values in a column.

-    `col_integer()`: the column should be interpreted as an integer.
-    `col_factor(levels, ordered = FALSE)`: the column should be interpreted as a factor with levels.

Work with *hotdogs.txt* data, which is a tab-delimited file without column names in the first row.
```{r}
hotdogs <- read_tsv("hotdogs.txt", 
                    col_names = c("type", "calories", "sodium"))
summary(hotdogs)
```
Define collector functions:
```{r}
fac <- col_factor(levels = c("Beef", "Meat", "Poultry"))
int <- col_integer()
```
Edit the `col_types` argument to import the data correctly:
```{r}
hotdogs_factor <- read_tsv("hotdogs.txt",
                           col_names = c("type", "calories", "sodium"),
                           col_types = list(fac, int, int))
summary(hotdogs_factor)
```

### 1.7 data.table: fread
The key performance metric for **data.table** package by Matt Dowle and Arun Srinvasan is speed. The package is mainly about data manipulation in R, but also features a super powerful function to read data: `fread()`. 
```{r}
library(data.table)
```
`fread()` is similar to `read.table()` but more convenient to use. Call `fread()` on *states.csv* with the first line as column names, and *states2.csv* without column names, both without additional arguments.
```{r}
fread("states.csv")
```
```{r}
fread("states2.csv") # fread makes up some column names itself.
```
`fread()` automatically deals with both cases without any specific arguments. It can also infer column types and the field separators without having to specify these. You can also manually specify the separator, the `colClasses`, the number of lines to skip or to read manually. `fread` is like an improved version of `read.table` which is faster, more convenient and adds functionality.

Import *potatoes.csv* with `fread()`:
```{r}
fread("potatoes.csv")
```
Import only columns 6 and 8 of *potatoes.csv*:
```{r}
fread("potatoes.csv", select = c(6, 8))
```
or using the column names:
```{r}
potatoes <- fread("potatoes.csv", select = c("texture", "moistness"))
```
Plot texture `x` and moistness `y` of potatoes:
```{r}
plot(potatoes$texture, potatoes$moistness)
```

The class of the result of `fread()` is both `data.table` and `data.frame`. `read_csv()` creates an object with three classes: `tbl_df`, `tbl` and `data.frame`.
